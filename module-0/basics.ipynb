{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0bc77f-f34a-4ef0-8e47-09e867e0954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228fa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "messages = [msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-02-11T17:08:11.917828128Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20002192613, 'load_duration': 18823694597, 'prompt_eval_count': 27, 'prompt_eval_duration': 717000000, 'eval_count': 25, 'eval_duration': 459000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-551a250b-bada-4e68-be33-550b371b6561-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_chat = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "model_1_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-02-11T17:08:30.325052095Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17138853442, 'load_duration': 16022755951, 'prompt_eval_count': 5, 'prompt_eval_duration': 770000000, 'eval_count': 16, 'eval_duration': 343000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-183832ea-80cb-486f-bb8b-356a90e9e639-0', usage_metadata={'input_tokens': 5, 'output_tokens': 16, 'total_tokens': 21})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_chat = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0)\n",
    "model_2_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.'},\n",
       " {'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) â€“ based AI agents. The agent executor class in the Langchain framework was the main tool for building and executing AI agents before LangGraph. Generative AI| Large Language Models| Building LLM Applications using Prompt Engineering| Building Your first RAG System using LlamaIndex| Stability.AI| MidJourney| Building Production Ready RAG systems using LlamaIndex| Building LLMs for Code| Deep Learning| Python| Microsoft Excel| Machine Learning| Decision Trees| Pandas for Data Analysis| Ensemble Learning| NLP| NLP using Deep Learning| Neural Networks| Loan Prediction Practice Problem| Time Series Forecasting| Tableau| Business Analytics'},\n",
       " {'url': 'https://cobusgreyling.medium.com/langgraph-from-langchain-explained-in-simple-terms-f7cd0c12cdbf',\n",
       "  'content': 'LangGraph is a method for creating state machines for conversational flow by defining them as graphs & itâ€™s easier to understand than you might think. Prompt chaining can be described as a technique used in working with language models, where multiple prompts (nodes) are sequentially linked (via edges) together to guide the generative app through a series of related tasks or steps. LangGraph is a module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. from langgraph.graph.message import add_messages   Intro to LangGraph - LangGraph ------------------------------ ### Build language agents as graphs langchain-ai.github.io'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs = TavilySearchResults(max_results=3).invoke(\"What is LangGraph?\")\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
