{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0bc77f-f34a-4ef0-8e47-09e867e0954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228fa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "messages = [msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-02-10T11:15:06.720072462Z', 'done': True, 'done_reason': 'stop', 'total_duration': 38270859913, 'load_duration': 31252197372, 'prompt_eval_count': 27, 'prompt_eval_duration': 6623000000, 'eval_count': 25, 'eval_duration': 382000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-0539b658-0c25-4890-9909-c7616971ffbf-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_chat = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "model_1_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-02-10T11:15:25.195839224Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17350211791, 'load_duration': 16233756686, 'prompt_eval_count': 5, 'prompt_eval_duration': 815000000, 'eval_count': 16, 'eval_duration': 299000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-486aa3ce-4982-47ea-972c-e6e851fa0b3f-0', usage_metadata={'input_tokens': 5, 'output_tokens': 16, 'total_tokens': 21})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_chat = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0)\n",
    "model_2_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.'},\n",
       " {'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) â€“ based AI agents. The agent executor class in the Langchain framework was the main tool for building and executing AI agents before LangGraph. Generative AI| Large Language Models| Building LLM Applications using Prompt Engineering| Building Your first RAG System using LlamaIndex| Stability.AI| MidJourney| Building Production Ready RAG systems using LlamaIndex| Building LLMs for Code| Deep Learning| Python| Microsoft Excel| Machine Learning| Decision Trees| Pandas for Data Analysis| Ensemble Learning| NLP| NLP using Deep Learning| Neural Networks| Loan Prediction Practice Problem| Time Series Forecasting| Tableau| Business Analytics'},\n",
       " {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'In this article, weâ€™ll introduce LangGraph, walk you through its basic concepts, and share some insights and common points of confusion for beginners. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next. Step 1: Define the Graph State First, we define the state structure for our graph. Step 4: Add Nodes to the Graph LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs = TavilySearchResults(max_results=3).invoke(\"What is LangGraph?\")\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
